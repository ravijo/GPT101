{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ogxw8dBTHyDL"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from contextlib import nullcontext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharLevelTokenizer:\n",
        "    \"\"\"Character-level tokenizer\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.char_to_id = {}\n",
        "        self.id_to_char = {}\n",
        "        self.vocab_size = 0\n",
        "\n",
        "    def build_vocab(self, texts):\n",
        "        \"\"\"Build vocabulary from texts\"\"\"\n",
        "        for text in sorted(\"\".join(texts)):\n",
        "            if text not in self.char_to_id:\n",
        "                self.char_to_id[text] = self.vocab_size\n",
        "                self.id_to_char[self.vocab_size] = text\n",
        "                self.vocab_size += 1\n",
        "        return self.vocab_size\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"Convert text to token IDs\"\"\"\n",
        "        return [self.char_to_id[char] for char in text]\n",
        "\n",
        "    def decode(self, ids):\n",
        "        \"\"\"Convert token IDs to text\"\"\"\n",
        "        return \"\".join(self.id_to_char[token_id] for token_id in ids)"
      ],
      "metadata": {
        "id": "J4erhx5gIl1x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\"One head of self-attention\"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)  # (B, T, C)\n",
        "        q = self.query(x)  # (B, T, C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))  # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1)  # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x)  # (B, T, C)\n",
        "        out = wei @ v  # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out"
      ],
      "metadata": {
        "id": "z2vRi2h2I--c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multiple heads of self-attention in parallel\"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "kab-ftJrJBST"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedFoward(nn.Module):\n",
        "    \"\"\"Simple linear layer followed by a non-linearity\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "HTM6H8HeJC_D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\"Transformer block: communication followed by computation\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "9VHQ-lnbJGVA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    \"\"\"GPT model\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)  # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx is (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx)  # (B, T, C)\n",
        "        pos_emb = self.position_embedding_table( torch.arange(T, device=device))  # (T, C)\n",
        "        x = tok_emb + pos_emb  # (B, T, C)\n",
        "        x = self.blocks(x)  # (B, T, C)\n",
        "        x = self.ln_f(x)  # (B, T, C)\n",
        "        logits = self.lm_head(x)  # (B, T, vocab_size)\n",
        "        return logits\n",
        "\n",
        "    def compute_loss(self, logits, targets):\n",
        "        B, T, C = logits.shape\n",
        "        logits = logits.view(B * T, C)\n",
        "        targets = targets.view(B * T)\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "        return loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T + 1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "PzrhlsvaJH30"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_first_column(filepath, skip_header=True):\n",
        "    \"\"\"read csv dataset\"\"\"\n",
        "    result = []\n",
        "    with open(filepath, encoding=\"utf-8\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        if skip_header:\n",
        "            next(reader)\n",
        "        for row in reader:\n",
        "            if row:\n",
        "                col = row[0]\n",
        "                if not col.upper().lstrip().startswith(\"AUDIENCE\"):\n",
        "                    result.append(col.partition(\":\")[2] or col.strip())\n",
        "    return \"\\n\".join(result)"
      ],
      "metadata": {
        "id": "dwIc2ssrJKFH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    \"\"\"Data loading\"\"\"\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i : i + block_size] for i in ix]).to(device)\n",
        "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix]).to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "cggiqTN_JL3C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    model.eval()\n",
        "    results = {}\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            with ctx:\n",
        "                logits = model(X)\n",
        "            loss = model.compute_loss(logits, Y)\n",
        "            losses[k] = loss.item()\n",
        "        results[split] = losses.mean()\n",
        "    model.train()\n",
        "    return results"
      ],
      "metadata": {
        "id": "j_9tKj68JNlf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128  # how many independent sequences will we process in parallel?\n",
        "block_size = 256  # what is the maximum context length for predictions?\n",
        "max_iters = 1000\n",
        "eval_interval = 100\n",
        "initial_lr = 3e-4\n",
        "min_lr = 1e-4\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 3\n",
        "n_layer = 3\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "c5OHfITsJPFm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "VsCTRdExJWX8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = read_first_column(\"train.csv\")\n",
        "val_text = read_first_column(\"test.csv\")"
      ],
      "metadata": {
        "id": "88b2h4pmJW0R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = CharLevelTokenizer()\n",
        "vocab_size = tokenizer.build_vocab(train_text)"
      ],
      "metadata": {
        "id": "dBhmzbiIJY6F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "train_data = torch.tensor(tokenizer.encode(train_text), dtype=torch.long)\n",
        "val_data = torch.tensor(tokenizer.encode(val_text), dtype=torch.long)"
      ],
      "metadata": {
        "id": "JsgO2Y9AJn6d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel()\n",
        "print(f\"{sum(p.numel() for p in model.parameters()) / 1e6} M parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHXjCmh5JpPY",
        "outputId": "d73278fa-536e-4d69-cf47-4a895bdd6cd4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.483604 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "hzxK-YakJquD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=initial_lr)\n",
        "lambda_func = lambda epoch: max(0.99 ** epoch, min_lr / initial_lr)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_func)"
      ],
      "metadata": {
        "id": "H9XIVEBMJsHF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = 'float32' # 'float32' or 'bfloat16'\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16}[dtype]\n",
        "ctx = nullcontext() if device == 'cpu' else torch.amp.autocast(device_type=device, dtype=ptdtype)\n",
        "model = torch.compile(model)"
      ],
      "metadata": {
        "id": "g_gXxs7ZJtfx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        t0 = time.time()\n",
        "        losses = estimate_loss()\n",
        "        t1 = time.time()\n",
        "        dt = t1 - t0\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}, time {dt:.1f} secs\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch(\"train\")\n",
        "\n",
        "    with ctx:\n",
        "        logits = model(xb)\n",
        "    loss = model.compute_loss(logits, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzE9UPZcJvg8",
        "outputId": "2fc915ae-142a-4e3b-eb01-c403d29c3407"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0422 12:25:43.018000 664 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.4782, val loss 4.4783, time 59.5 secs\n",
            "step 100: train loss 2.3640, val loss 2.3625, time 48.5 secs\n",
            "step 200: train loss 2.2858, val loss 2.2879, time 48.3 secs\n",
            "step 300: train loss 1.8112, val loss 1.8150, time 48.0 secs\n",
            "step 400: train loss 1.5471, val loss 1.5508, time 48.0 secs\n",
            "step 500: train loss 1.4154, val loss 1.4198, time 48.0 secs\n",
            "step 600: train loss 1.3373, val loss 1.3449, time 47.9 secs\n",
            "step 700: train loss 1.2834, val loss 1.2923, time 47.9 secs\n",
            "step 800: train loss 1.2416, val loss 1.2529, time 48.0 secs\n",
            "step 900: train loss 1.2066, val loss 1.2177, time 47.4 secs\n",
            "step 999: train loss 1.1870, val loss 1.2010, time 46.8 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctx = torch.tensor(tokenizer.encode(\"A\"), dtype=torch.long).unsqueeze(0).to(device)\n",
        "out = tokenizer.decode(model.generate(ctx, max_new_tokens=1000)[0].tolist())\n",
        "print(out)"
      ],
      "metadata": {
        "id": "dBDCh2O5JzqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878eb417-795e-4532-aaa5-2b2b35117ea1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And Howere he Connell.\n",
            "I countries it going to park it states the United States.\n",
            "In the President oneas to aske Forces theses in West-Mal DFranahtra, States Prelss, Rerus systeday, no leaganization will tak and mystem find Auguss in administratione.\n",
            "When you have people imme right.\n",
            "I think that we will ide look be close is the President who made aleave into he schance to have accern and socantal Situgal of Ame wities. Secondle Bring lock. Heys notrow Department of the appoint that lack to it our pappointsmit to way and strength, come interestain.\n",
            "The United States Administrationiter and controvernment this appening areapted overnovulved some oppmeonened the nations of border, I was anything that will do it.\n",
            "And will lead that the Fed that competition address will falw.\n",
            "Sememember with tis supportant seell you bime the has a vrick and derical light year and like it going to is the it to fight. We some ole backly with message in throus with and yeal I think commembat?\n",
            " Its talk about, thi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch"
      ],
      "metadata": {
        "id": "1t1Q7A4m6FSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e069323-5a0a-4260-c053-3f2451a4d2a9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.6.0+cu124\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchvision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wv5-8h1G6aHp"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}